
\chapter{Evaluation}\label{sec:evaluation}

This chapter is aimed to demonstrate that applying LETOR technique improves the effectiveness of the expert search system. 
It separates into 2 experiments. The first experiment does not make use of K-fold Cross-validation technique (see Section~\ref{sec:withoutLETOR})
but the second experiment does (see Section~\ref{sec:withLETOR}).
We use LETOR technique proposed in Chapter~\ref{sec:letor}. Basically, there are 2 necessary datasets: training and testing datasets and 1 optional dataset:
validation dataset. In IR, we refer them as training, testing and validation queries respectively. 
Some of the queries were provided by Dr. Craig Macdonald and the others were made up by myself. 
We made an assumption that the current system (using only publication as expertise evidence) is effective. This means that relevance judgements 
(the experts retrieved in response to a query) can be obtained manually from the current system. To make relevance judgements, top 20 experts retrieved in response to a query
are examined if they are truly an expert by visiting their official home page and with the help of Dr. Craig Macdonald.
Since constructing relevance judgements is time-consuming, we have made only 67 queries manually. 
Throughout this chapter, the queries annotated by * denote queries whose relevant experts are restricted to those experts only from 
the University of Glasgow. It is difficult to judge experts not in the University of Glasgow because we 
do not know them. However, in practice, this will incur dataset quality~\cite{craig}.

Before we discuss evaluation, we should have some goals set up. This is necessary because the evaluation results can be compared against the goals in order to
conclude whether all goals are achieved or not. As stated in Chapter~\ref{section:aims}, our goal is to integrate new kind of expertise evidence, funded projects,
with existing expertise evidence, publications, to enhance the effectiveness of the expert search system. At the end of this chapter, we have to be able to 
answer the following question:

\begin{quotation}
 \textit{Does integrating funded projects with publications using learning to rank technique (LETOR) help improve the performance 
 of the expert search system?}
\end{quotation}

We refer to a currently deployed SICSA expert search system (without Learning to Rank) as our \textit{baseline}. This term will be frequently used 
throughout this chapter.

\section{Evaluation Without K-fold Cross-validation}\label{sec:withoutLETOR}
This section is aimed to demonstrate that applying LETOR technique improves the effectiveness of the deployed expert search system. 
K-fold Cross-validation technique is not applied in this section.

\subsection{Experimental Setting}
 The following is a list of steps in running an evaluation:
\begin{enumerate}
 \item from testing queries, generate a qrels file as discussed in Chapter~\ref{sec:treceval}.
 \item generate 2 learned models (see Chapter~\ref{section:producelearnedmodel}) from training LETOR file using AdaRank, and Coordinate Ascent algorithms.
 \item apply each learned model to all testing queries.
 \item for each learned model, apply it to LETOR file of testing queries using RankLib and generate a result file in TREC format (see Chapter~\ref{sec:treceval}) 
 \item evaluate the result file in TREC format with the qrels file for each test using trec\_eval (see Chapter~\ref{sec:treceval}).
\end{enumerate}

To evaluate our baseline, we can set other feature values apart from publication query feature value to 0 and perform step (5).

\subsubsection{Training Queries}
34 queries shown in table~\ref{table:trainingqueries} are used for training. 

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|c|l|c|l|}
\hline \textbf{\#} & \textbf{Query} & \textbf{\#} & \textbf{Query} \\
\hline 1 & *language modelling & 18 & game theory\\
\hline 2 & *manets & 19 & stable marriage \\
\hline 3  & *match & 20 & quantum computation\\ 
\hline 4  & *multimodal & 21 & constraint modelling\\ 
\hline 5  & *music as navigation cues & 22 & home networks\\ 
\hline 6  & networking security & 23 & wireless sensor networks\\ 
\hline 7  & *neural network & 24 & distributed systems\\ 
\hline 8  & *older adults use of computers & 25 & operating system\\ 
\hline 9  & *parallel logic programming & 26 & *terrier\\ 
\hline 10  & *query expansion & 27 & *text searching\\ 
\hline 11  & *road traffic accident statistics & 28 & *trec collection class\\ 
\hline 12  & *shoogle & 29 & *usability\\ 
\hline 13  & *skill-based behavior & 30 & *utf support terrier\\ 
\hline 14  & *sound in multimedia human-computer interfaces & 31 & *visual impairment\\ 
\hline 15  & statistical inference & 32 & *wafer fab cost \\ 
\hline 16  & *suffix tree & 33 & database\\ 
\hline 17  & mobile hci & 34 & programming languages\\ 
\hline
\end{tabular}
}
\caption{Training Queries} \label{table:trainingqueries}
\end{table}

\subsubsection{Testing Queries}
33 queries are used for testing as shown in table~\ref{table:testingqueries}.
\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|c|l|c|l|}
\hline \textbf{\#} & \textbf{Query} & \textbf{\#} & \textbf{Query} \\
\hline 1 & *empirical methods & 18 & *3d human body segmentation\\
\hline 2 & *eurosys 2008 & 19 & *anchor text \\
\hline 3  & *facial reconstruction & 20 & *clustering algorithms\\ 
\hline 4  & *force feedback & 21 & *different matching coefficients\\ 
\hline 5  & functional programming & 22 & *discrete event simulation\\ 
\hline 6  & *glasgow haskell compiler & 23 & *discrete mathematics\\ 
\hline 7  & *grid computing & 24 & *distributed predator prey\\ 
\hline 8  & artificial intelligence & 25 & *divergence from randomness\\ 
\hline 9  & computer graphics & 26 & *ecir 2008 \\
\hline 10  & robotics & 27 & *group response systems\\ 
\hline 11  & data mining & 28 & *handwriting pin\\ 
\hline 12  & computer vision & 29 & *haptics\\ 
\hline 13  & information security & 30 & *haptic visualisation\\ 
\hline 14  & *3d audio & 31 & *hci issues in mobile devices\\ 
\hline 15  & expert search & 32 & *human error health care \\ 
\hline 16  & information retrieval & 33 & *information extraction\\ 
\hline 17  & machine translation &  & \\ 
\hline
\end{tabular}
}
\caption{Testing Queries} \label{table:testingqueries}
\end{table}

\subsection{Experimental Results}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|c|c|c|c|c|}
\hline \textbf{Algorithm} & \textbf{MAP} & \textbf{NDCG} & \textbf{MRR} & \textbf{Number of Relevant Experts}\\
\hline AdaRank & 0.0153 & 0.1872 & 0.0116 & 106\\
\hline Coordinate Ascent & 0.5264 & 0.6618 & 0.6332 & 106 \\
\hline Baseline  & 0.5499 & 0.6871 & 0.6484 & 106\\ 
\hline
\end{tabular}
}
\caption{Evaluation Results} \label{table:evaluationresult}
\end{table}

Table~\ref{table:evaluationresult} shows the retrieval effectiveness of the proposed LETOR techniques and baseline. It can be clearly seen
that overall the baseline gives better performance compared to using LETOR considering MAP, NDCG and MRR evaluation metrics. Coordinate Ascent gives second best 
performance. Therefore, the answer to the question is NO, using LETOR technique (without K-fold Cross-validation) does not enhance the 
effectiveness of the deployed expert search system.

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|c|c|c|c|c|c|}
\hline \textbf{Testing Queries} & \multicolumn{2}{|c|}{\textbf{AdaRank}} & \multicolumn{2}{|c|}{\textbf{Coordinate Ascent}} & \multicolumn{2}{|c|}{\textbf{Baseline}} \\
\hline 				 & \textbf{MAP} & \textbf{MRR}  & \textbf{MAP} & \textbf{MRR}  & \textbf{MAP} & \textbf{MRR} \\
\hline *3d audio & 0.0053 & 0.0053 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline *3d human body segmentation & 0.0127 & 0.0068 & 0.1452 & 0.2000 & 0.1824 & 0.2000 \\
\hline *anchor text & 0.0263 & 0.0088 & 0.7894 & 1.0000 & 0.7894 & 1.0000 \\
\hline artificial intelligence & 0.0344 & 0.0233 & 0.5944 & 1.0000 & 0.5972 & 1.0000 \\
\hline *clustering algorithms & 0.0166 & 0.0071 & 0.3048 & 0.2000 & 0.3048 & 0.2000 \\
\hline computer graphics & 0.0047 & 0.0047 & 0.5000 & 0.5000 & 0.5000 & 0.5000 \\
\hline computer vision & 0.0142 & 0.0130 & 0.4611 & 0.5000 & 0.4611 & 0.5000 \\
\hline data mining & 0.0181 & 0.0118 & 0.9167 & 1.0000 & 0.9167 & 1.0000 \\
\hline *different matching coefficients & 0.0091 & 0.0063 & 0.5833 & 0.5000 & 0.5833 & 0.5000 \\
\hline *discrete event simulation & 0.0078 & 0.0078 & 0.3333 & 0.3333 & 0.3333 & 0.3333 \\
\hline *discrete mathematics & 0.0164 & 0.0115 & 0.0306 & 0.0400 & 0.1394 & 0.1250 \\
\hline *distributed predator prey & 0.0058 & 0.0058 & 0.0037 & 0.0037 & 0.1111 & 0.1111 \\
\hline *divergence from randomness & 0.0124 & 0.0058 & 0.9167 & 1.0000 & 0.9167 & 1.0000 \\
\hline *ecir 2008 & 0.0152 & 0.0070 & 0.8125 & 1.0000 & 0.8125 & 1.0000 \\
\hline *empirical methods & 0.0189 & 0.0072 & 0.2092 & 0.1667 & 0.2154 & 0.1667 \\
\hline *eurosys 2008 & 0.0055 & 0.0055 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline expert search & 0.0107 & 0.0075 & 0.5037 & 1.0000 & 0.5227 & 1.0000 \\
\hline *facial reconstruction & 0.0039 & 0.0039 & 0.0021 & 0.0021 & 0.2000 & 0.2000 \\
\hline *force feedback & 0.0073 & 0.0050 & \textbf{0.6429} & 1.0000 & 0.6250 & 1.0000 \\
\hline functional programming & 0.0244 & 0.0112 & 0.1687 & 0.2000 & 0.2038 & 0.1429 \\
\hline *glasgow haskell compiler & 0.0101 & 0.0101 & 0.3333 & 0.3333 & 0.5000 & 0.5000 \\
\hline *grid computing & 0.0123 & 0.0083 & 0.3095 & 0.3333 & 0.3333 & 0.3333 \\
\hline *group response systems & 0.0054 & 0.0054 & 0.5000 & 0.5000 & 0.5000 & 0.5000 \\
\hline *handwriting pin & 0.0054 & 0.0038 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline *haptic visualisation & 0.0224 & 0.0102 & \textbf{0.6111} & 1.0000 & 0.5861 & 1.0000 \\
\hline *haptics & 0.0407 & 0.0133 & 0.4929 & 0.5000 & 0.5819 & 0.5000 \\
\hline *hci issues in mobile devices & 0.0268 & 0.0091 & 0.5821 & 1.0000 & 0.6160 & 1.0000 \\
\hline *human error health care & 0.0064 & 0.0064 & \textbf{0.5821} & \textbf{1.0000} & 0.3333 & 0.3333 \\
\hline *information extraction & 0.0069 & 0.0050 & \textbf{0.3333} & \textbf{0.3333} & 0.2500 & 0.2500 \\
\hline information retrieval & 0.0308 & 0.0102 & \textbf{0.7496} & 1.0000 & 0.7468 & 1.0000 \\
\hline information security & 0.0163 & 0.0120 & 0.7333 & 1.0000 & 0.7333 & 1.0000 \\
\hline machine translation & 0.0117 & 0.0118 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline robotics & 0.0404 & 0.1111 & \textbf{0.5565} & 1.0000 & 0.5523 & 1.0000\\
\hline

\end{tabular}
}
\caption{Evaluation Results of Each Testing Query} \label{table:eachqueryevaluationresult}
\end{table}

Table~\ref{table:eachqueryevaluationresult} shows the evaluation results of each testing query. Numbers in \textbf{bold}
are numbers higher than ones in the baseline. It has shown that applying LETOR technique using
Coordinate Ascent algorithm to the testing queries shown in table~\ref{table:table:baselineQ} outperformed baseline ones considering MAP/MRR values.
The experts in \textbf{bold} indicates that using Coordinate Ascent they are ranked higher higher than baseline. N/A indicates that the experts 
are not in the top ten experts.

\begin{table}
\centering
 \scalebox{0.5}{
\begin{tabular}{|l|l|c|c|c|}
  \hline \textbf{Testing Queries} & \multicolumn{1}{|c|}{\textbf{Expert}} & \textbf{Grade} & \textbf{Rank (Coordinate Ascent)} & \textbf{Rank (Baseline)} \\
 
    \hline *force feedback & Stephen Brewster & 2 & 1 & 1 \\
   \hline  		 & Roderick Murray-Smith & 2 & N/A & N/A \\
   \hline *human error health care & Stephen Robert & 1 & 3 & 3 \\
   \hline *information extraction & Joemon Jose & 2 & 8 & 8 \\
   \hline 			& Alessandro Vinciarelli & 1 & 4 & 4 \\
   \hline *haptic visualisation & Stephen Brewster & 2 & 1 & 1 \\
   \hline 			& Roderick Murray-Smith & 2 & N/A & 5 \\
   \hline 			& \textbf{John Williamson} & 2 & 4 & 9 \\
   \hline 			& Phillip Gray & 2 & N/A & 6 \\
   \hline information retrieval & Joemon Jose (Glasgow University) & 2 & 1 & 1 \\
               \end{tabular}
}
\label{table:baselineQ}
\end{table}

\begin{itemize}
 \item force feedback
 \item haptic visualisation
 \item human error heath care
 \item information extraction
 \item information retrieval
 \item robotics
\end{itemize}

\section{Evaluation With K-fold Cross-validation}\label{sec:withLETOR}
In the previous section, the evaluation results have shown that applying LETOR makes the deployed expert search system perform poorer. 
This section aims to evaluate the effectivenes of the system by applying K-fold Cross-validation
technique described in Chapter~\ref{sec:kfold}. We decided to choose $K = 5$. This is fairly normal for learning to rank~\cite{craig}.
Higher K is possible, but that infers that the LETOR needs more training. RankLib provides K-fold Cross-validation functionality. However, we will not
use this functionality because some of our datasets results were restricted to those experts only from the University of Glasgow. For this reason, the datasets should
be split into training, validation and testing queries manually to avoid one of them having only experts from University of Glasgow~\cite{craig}.

\subsection{Experimental Setting}

As discussed earlier, we decided to choose $K = 5$ for K-fold Cross-validation. Each of the 5 folds has all of the queries: 60\% for training, 
20\% for validation and 20\% for testing~\cite{kfoldcv}. Across the 5 folds, each query will appear 3 times in training, once in validation and 
once in testing queries. For each fold, training queries are trained and validated by validation queries to obtain a learned model.
Then a learned model for each fold is applied to testing queries of that fold. Results of each run across the 5 folds are combined into one results file in
TREC format. With the qrels file, this results file is then evaluated with trec\_eval. Finally, one of the learned models is used by the system.

\subsubsection{Fold 1}
Tables~\ref{table:fold1testing},~\ref{table:fold1training} and~\ref{table:fold1validating} show testing, training and validation queries respectively.

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|l|}

\hline \multicolumn{2}{|c|}{\textbf{Training Queries}} \\
\hline *grid computing & *haptics \\
\hline *hci issues in mobile devices & *neural network \\
\hline operating system & computer vision\\
\hline functional programming & *divergence from randomness\\ 
\hline quantum computation & *facial reconstruction \\
\hline *clustering algorithms & *eurosys 2008\\ 
\hline *glasgow haskell compiler & *human error health care \\
\hline *query expansion & *terrier \\ 
\hline *different matching coefficients & *distributed predator prey \\
\hline *parallel logic programming & information security\\ 
\hline information retrieval & *group response systems\\
\hline expert search & distributed systems\\ 
\hline *empirical methods & *handwriting pin\\
\hline machine translation & artificial intelligence\\
\hline computer graphics & *force feedback\\
\hline *wafer fab cost & *haptic visualisation\\
\hline *3d audio & *3d human body segmentation\\
\hline *discrete event simulation & *anchor text\\
\hline data mining & robotics\\
\hline *discrete mathematics & *ecir 2008\\
\hline programming languages & *information extraction \\
\hline
\end{tabular}
}
\caption{Training Queries for Fold 1} \label{table:fold1training}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Testing Queries}} \\
\hline *usability \\
\hline stable marriage \\
\hline constraint modelling \\
\hline mobile hci \\ 
\hline *language modelling \\
\hline home networks \\ 
\hline *multimodal \\
\hline networking security \\ 
\hline *suffix tree \\
\hline *sound in multimedia human-computer interfaces \\ 
\hline wireless sensor networks \\
\hline game theory \\ 
\hline *visual impairment \\
\hline
\end{tabular}
}
\caption{Testing Queries for Fold 1} \label{table:fold1testing}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Validation Queries}} \\
\hline programming languages \\
\hline *text searching \\
\hline *older adults use of computers \\
\hline *music as navigation cues \\ 
\hline *statistical inference \\
\hline *road traffic accident statistics \\ 
\hline *shoogle \\
\hline *skill-based behavior \\ 
\hline database \\
\hline *manets \\ 
\hline *suffix tree \\
\hline *trec collection class \\ 
\hline *matching \\
\hline
\end{tabular}
}
\caption{Validation Queries for Fold 1} \label{table:fold1validating}
\end{table}

\subsubsection{Fold 2}
Tables~\ref{table:fold2testing},~\ref{table:fold2training} and~\ref{table:fold2validating} show testing, training and validation queries respectively.
\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|l|}

\hline \multicolumn{2}{|c|}{\textbf{Training Queries}} \\
\hline *grid computing & *older adults use of computers \\
\hline operating system & *statistical inference \\
\hline functional programming & quantum computation \\
\hline *clustering algorithms & *glasgow haskell compiler \\ 
\hline *query expansion & *parallel logic programming \\
\hline expert search & information retrieval \\ 
\hline *suffix tree & machine translation \\
\hline computer graphics & *discrete event simulation \\ 
\hline *wafer fab cost & *discrete mathematics \\
\hline data mining & *text searching \\ 
\hline programming languages & *haptics \\
\hline *neural network & *road traffic accident statistics \\ 
\hline *music as navigation cues & *eurosys 2008 \\
\hline *facial reconstruction & *shoogle \\
\hline *human error health care & *terrier \\
\hline *distributed predator prey & database \\
\hline *skill-based behavior & distributed systems \\
\hline artificial intelligence & *force feedback \\
\hline *manets & *anchor text \\
\hline *trec collection class & robotics \\
\hline *match & *ecir 2008 \\
\hline
\end{tabular}
}
\caption{Training Queries for Fold 2} \label{table:fold2training}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Testing Queries}} \\
\hline *different matching coefficients \\
\hline *haptics \\
\hline *hci issues in mobile devices \\
\hline computer vision \\ 
\hline *empirical methods \\
\hline *divergence from randomness \\ 
\hline *haptic visualisation \\
\hline *3d human body segmentation \\ 
\hline information security \\
\hline *group response systems \\ 
\hline *handwriting pin \\
\hline *information extraction \\ 
\hline *3d audio \\
\hline
\end{tabular}
}
\caption{Testing Queries for Fold 2} \label{table:fold2testing}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Validation Queries}} \\
\hline *usability \\
\hline *stable marriage \\
\hline constraint modelling \\
\hline *mobile hci \\ 
\hline *language modelling \\
\hline home networks \\ 
\hline *multimodal \\
\hline networking security \\ 
\hline *suffix tree \\
\hline *sound in multimedia human-computer interfaces \\ 
\hline *wireless sensor networks \\
\hline game theory \\ 
\hline *visual impairment \\
\hline
\end{tabular}
}
\caption{Validation Queries for Fold 2} \label{table:fold2validating}
\end{table}

\subsubsection{Fold 3}
Tables~\ref{table:fold3testing},~\ref{table:fold3training} and~\ref{table:fold3validating} show testing, training and validation queries respectively.
\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|l|}

\hline \multicolumn{2}{|c|}{\textbf{Training Queries}} \\
\hline *older adults use of computers & constraint modelling \\
\hline operating system & *multimodal \\
\hline *statistical inference & quantum computation \\
\hline *query expansion & *usability \\ 
\hline stable marriage & *parallel logic programming \\
\hline information retrieval & expert search \\ 
\hline home networks & networking security \\
\hline *suffix tree & *wireless sensor networks \\ 
\hline computer graphics & *wafer fab cost \\
\hline game theory & *visual impairment \\ 
\hline programming languages & *text searching \\
\hline *neural network & mobile hci \\ 
\hline *road traffic accident statistics & *facial reconstruction \\
\hline *music as navigation cues & *shoogle \\
\hline *terrier & *sound in multimedia human-computer interfaces \\
\hline distributed systems & skill-based behavior \\
\hline database & *force feedback \\
\hline *language modelling & *manets \\
\hline *trec collection class & *match \\
\hline
\end{tabular}
}
\caption{Training Queries for Fold 3} \label{table:fold3training}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Testing Queries}} \\
\hline *discrete event simulation \\
\hline data mining \\
\hline *discrete mathematics \\
\hline *grid computing \\ 
\hline *haptics \\
\hline *eurosys 2008 \\ 
\hline functional programming \\
\hline *human error health care \\ 
\hline *distributed predator prey \\
\hline *clustering algorithms \\ 
\hline *glasgow haskell compiler \\
\hline artificial intelligence \\ 
\hline expert search \\
\hline *anchor text \\
\hline robotics \\
\hline *machine translation \\
\hline *ecir 2008 \\
\hline
\end{tabular}
}
\caption{Testing Queries for Fold 3} \label{table:fold3testing}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Validation Queries}} \\
\hline *different matching coefficients \\
\hline *haptics \\
\hline *hci issues in mobile devices \\
\hline computer vision \\ 
\hline *empirical methods \\
\hline *divergence from randomness \\ 
\hline *haptic visualisation \\
\hline *3d human body segmentation \\ 
\hline information security \\
\hline *group response systems \\ 
\hline *handwriting pin \\
\hline *information extraction \\ 
\hline *3d audio \\
\hline
\end{tabular}
}
\caption{Validation Queries for Fold 3} \label{table:fold3validating}
\end{table}

\subsubsection{Fold 4}
Tables~\ref{table:fold4testing},~\ref{table:fold4training} and~\ref{table:fold4validating} show testing, training and validation queries respectively.
\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|l|}

\hline \multicolumn{2}{|c|}{\textbf{Training Queries}} \\
\hline *older adults use of computers & *constraint modelling \\
\hline *hci issues in mobile devices & *multimodal \\
\hline *statistical inference & *usability \\
\hline *different matching coefficients & stable marriage \\ 
\hline *empirical methods & home networks \\
\hline networking security & *suffix tree \\ 
\hline wireless sensor networks & game theory \\
\hline *visual impairment & *3d audio \\ 
\hline *haptics & programming languages \\
\hline *text searching & mobile hci \\ 
\hline computer vision & *divergence from randomness \\
\hline *road traffic accident statistics & *music as navigation cues \\ 
\hline *shoogle & *sound in multimedia human-computer interfaces \\
\hline information security & *group response systems \\
\hline *skill-based behavior & database \\
\hline *handwriting pin & *language modelling \\
\hline *manets & *haptic visualisation \\
\hline *3d human body segmentation & *trec collection class \\
\hline *match & *information extraction \\
\hline
\end{tabular}
}
\caption{Training Queries for Fold 4} \label{table:fold4training}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Testing Queries}} \\
\hline programming languages \\
\hline *neural network \\
\hline operating system \\
\hline *facial reconstruction \\ 
\hline quantum computation \\
\hline *terrier \\ 
\hline distributed systems \\
\hline *query expansion \\ 
\hline *force feedback \\
\hline *parallel logic programming \\ 
\hline expert search \\
\hline information retrieval \\ 
\hline computer graphics \\
\hline *wafer fab cost \\
\hline
\end{tabular}
}
\caption{Testing Queries for Fold 4} \label{table:fold4testing}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Validation Queries}} \\
\hline *discrete event simulation \\
\hline data mining \\
\hline *discrete mathematics \\
\hline *grid computing \\ 
\hline *haptics \\
\hline *eurosys 2008 \\ 
\hline functional programming \\
\hline *human error health care \\ 
\hline *distributed predator prey \\
\hline *clustering algorithms \\ 
\hline *glasgow haskell compiler \\
\hline artificial intelligence \\ 
\hline expert search \\
\hline *anchor text \\
\hline robotics \\
\hline machine translation \\
\hline *ecir 2008 \\
\hline
\end{tabular}
}
\caption{Validation Queries for Fold 4} \label{table:fold4validating}
\end{table}

\subsubsection{Fold 5}

Tables~\ref{table:fold5testing},~\ref{table:fold5training} and~\ref{table:fold5validating} show testing, training and validation queries respectively.

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|l|}

\hline \multicolumn{2}{|c|}{\textbf{Training Queries}} \\
\hline *grid computing & constraint modelling \\
\hline *hci issues in mobile devices & *multimodal \\
\hline functional programming & *clustering algorithms \\
\hline *glasgow haskell compiler & *usability \\ 
\hline *different matching coefficients & stable marriage \\
\hline expert search & *empirical methods \\ 
\hline home networks & networking security \\
\hline *suffix tree & machine translation \\ 
\hline *wireless sensor networks & game theory \\
\hline *visual impairment & *3d audio \\ 
\hline *discrete event simulation & data mining \\
\hline *discrete mathematics & *haptics \\ 
\hline mobile hci & computer vision \\
\hline *divergence from randomness & *eurosys 2008 \\
\hline *human error health care & *distributed predator prey \\
\hline *sound in multimedia human-computer interfaces & information security \\
\hline *group response systems & *handwriting pin \\
\hline artificial intelligence & language modelling\\
\hline *haptic visualisation & *3d human body segmentation \\
\hline *anchor text & robotics \\
\hline *ecir 2008 & *information extraction \\
\hline
\end{tabular}
}
\caption{Training Queries for Fold 5} \label{table:fold5training}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Testing Queries}} \\
\hline programming languages \\
\hline *text searching \\
\hline *older adults use of computers \\
\hline *music as navigation cues \\ 
\hline *statistical inference \\
\hline *road traffic accident statistics \\ 
\hline *shoogle \\
\hline *skill-based behavior \\ 
\hline database \\
\hline *manets \\ 
\hline *suffix tree \\
\hline *trec collection class \\ 
\hline *match \\
\hline
\end{tabular}
}
\caption{Testing Queries for Fold 5} \label{table:fold5testing}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|}
\hline \multicolumn{1}{|c|}{\textbf{Validation Queries}} \\
\hline programming languages \\
\hline *neural network \\
\hline operating system \\
\hline *facial reconstruction \\ 
\hline quantum computation \\
\hline *terrier \\ 
\hline distributed systems \\
\hline *query expansion \\ 
\hline *force feedback \\
\hline *parallel logic programming \\ 
\hline expert search \\
\hline information retrieval \\ 
\hline computer graphics \\
\hline *wafer fab cost \\
\hline
\end{tabular}
}
\caption{Validation Queries for Fold 5} \label{table:fold5validating}
\end{table}

\subsection{Experimental Results}

Table~\ref{table:kfoldevaluationresult} shows the retrieval effectiveness of the proposed LETOR techniques using K-fold cross-validation techinque
and retrieval effectiveness of the baseline.
It can be clearly seen that overall the baseline is still better than LETOR using K-fold cross-validation. 
Coordinate Ascent still gives second best performance. But using K-fold cross-validation technique, the effectiveness is slightly better than
not using K-fold cross-validation (discussed in the last section). Therefore, the answer
to the question is still NO, using LETOR technique with K-fold cross-validation does not enhance the effectiveness of the deployed expert search system.
Table~\ref{table:kfoldqueryresult} shows the evaluation results of each testing query. Numbers in \textbf{bold} show testing queries applying Coordinate Ascent 
whose evaluation metrics are higher
than baseline ones. Numbers underlined show that testing queries applying AdaRank algorithm perform better than ones applying Coordinate Ascent.
The evaluation results of the testing queries applied with LETOR using Coordinate Ascent given below outperform baseline ones technique considering MAP/MRR values:
\begin{itemize}
 \item artificial intelligence
 \item ecir 2008
 \item force feedback
 \item information retrieval
\end{itemize}


\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|c|c|c|c|c|}
\hline \textbf{Algorithm} & \textbf{MAP} & \textbf{NDCG} & \textbf{MRR} & \textbf{Number of Relevant Experts}\\
\hline AdaRank & 0.0469 & 0.2397 & 0.0843 & 106 \\
\hline Coordinate Ascent & 0.5321 & 0.6703 & 0.6366 & 106 \\
\hline Without LETOR  & 0.5499 & 0.6871 & 0.6484 & 106 \\ 
\hline
\end{tabular}
}
\caption{Evaluation Results Using K-fold Cross-validation} \label{table:kfoldevaluationresult}
\end{table}

\begin{table}
\centering
\scalebox{0.5}{\begin{tabular}{|l|c|c|c|c|c|c|}
\hline \textbf{Testing Queries} & \multicolumn{2}{|c|}{\textbf{AdaRank}} & \multicolumn{2}{|c|}{\textbf{Coordinate Ascent}} & \multicolumn{2}{|c|}{\textbf{Without LETOR}} \\
\hline 				 & \textbf{MAP} & \textbf{MRR}  & \textbf{MAP} & \textbf{MRR}  & \textbf{MAP} & \textbf{MRR} \\
\hline 3d audio & 0.0227 & 0.0227 & 1.0000 & 1.0000 & 1.0000 & 1.0000\\
\hline 3d human body segmentation & 0.0239 & 0.0222 & 0.1824 & 0.2000 & 0.1824 & 0.2000 \\
\hline anchor text & 0.0263 & 0.0088 & 0.7894 & 1.0000 & 0.7894 & 1.0000 \\
\hline artificial intelligence & 0.0344 & 0.0233 & \textbf{0.6064} & 1.0000 & 0.5972 & 1.0000 \\
\hline clustering algorithms & 0.0166 & 0.0071 & 0.3048 & 0.2000 & 0.3048 & 0.2000 \\
\hline computer graphics & 0.1429 & 0.1429 & 0.5000 & 0.5000 & 0.5000 & 0.5000 \\
\hline computer vision & 0.0430 & 0.0667 & 0.4611 & 0.5000 & 0.4611 & 0.5000 \\
\hline data mining & 0.0181 & 0.0118 & 0.9167 & 1.0000 & 0.9167 & 1.0000 \\
\hline different matching coefficients & 0.0076 & 0.0052 & 0.5833 & 0.5000 & 0.5833 & 0.5000 \\
\hline discrete event simulation & 0.0078 & 0.0078 & 0.3333 & 0.3333 & 0.3333 & 0.3333 \\
\hline discrete mathematics & 0.0164 & 0.0115 & 0.1214 & 0.1000 & 0.1394 & 0.1250 \\
\hline distributed predator prey & \uline{0.0058} & \uline{0.0058} & 0.0038 & 0.0038 & 0.1111 & 0.1111 \\
\hline divergence from randomness & 0.0205 & 0.0122 & 0.9167 & 1.0000 & 0.9167 & 1.0000 \\
\hline ecir 2008 & 0.0152 & 0.0070 & \textbf{0.8304} & 1.0000 & 0.8125 & 1.0000 \\
\hline empirical methods & 0.0316 & 0.0286 & 0.2154 & 0.1667 & 0.2154 & 0.1667 \\
\hline eurosys 2008 & 0.0055 & 0.0055 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline expert search & 0.0106 & 0.0076 & 0.5040 & 1.0000 & 0.5227 & 1.0000 \\
\hline facial reconstruction & 0.0270 & 0.0270 & 0.1429 & 0.1429 & 0.2000 & 0.2000 \\
\hline force feedback & 0.5141 & 1.0000 & \textbf{0.6429} & 1.0000 & 0.6250 & 1.0000 \\
\hline functional programming & 0.0244 & 0.0112 & 0.0952 & 0.1111 & 0.2038 & 0.1429 \\
\hline glasgow haskell compiler & 0.0101 & 0.0101 & 0.3333 & 0.3333 & 0.5000 & 0.5000 \\
\hline grid computing & 0.0123 & 0.0083 & 0.3333 & 0.3333 & 0.3333 & 0.3333 \\
\hline group response systems & 0.0047 & 0.0047 & 0.5000 & 0.5000 & 0.5000 & 0.5000 \\
\hline handwriting pin & 0.0422 & 0.0400 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline haptic visualisation & 0.0328 & 0.0400 & 0.5861 & 1.0000 & 0.5861 & 1.0000 \\
\hline haptics & 0.0331 & 0.0104 & 0.4091 & 0.5000 & 0.5819 & 0.5000 \\
\hline hci issues in mobile devices & 0.0319 & 0.0357 & 0.6160 & 1.0000 & 0.6160 & 1.0000 \\
\hline human error health care & 0.0064 & 0.0064 & 0.3333 & 0.3333 & 0.3333 & 0.3333 \\
\hline information extraction & 0.0254 & 0.0217 & 0.2500 & 0.2500 & 0.2500 & 0.2500 \\
\hline information retrieval & 0.2538 & 1.0000 & \textbf{0.7622} & \textbf{1.0000} & 0.7468 & 0.7468 \\
\hline information security & 0.0275 & 0.0476 & 0.7333 & 1.0000 & 0.7333 & 1.0000 \\
\hline machine translation & 0.0117 & 0.0118 & 1.0000 & 1.0000 & 1.0000 & 1.0000 \\
\hline robotics & 0.0404 & 0.1111 & 0.5523 & 1.0000 & 0.5523 & 1.0000 \\
\hline
\end{tabular}
}
\caption{Evaluation Results of Each Testing Query Using K-fold Cross-validation} \label{table:kfoldqueryresult}
\end{table}

\section{Causes of Learning to Rank Failure}
It has shown in the last section that applying LETOR technique fails. The followings are reasons behind it~\cite{craig}:
\begin{itemize}
 \item The size of training/validation dataset is not big enough.
 \item Selected LETOR Features are not very useful.
 \item The number of publications and funded projects is not balanced. We have 22225 publications but only 369 funded projects. This results in 
 features related to publications outweighing funded project features in both query dependent and independent features.
\end{itemize}
For AdaRank, the performance is considerably poorer than Coordinate Ascent because AdaRank requires a large set of validation data to avoid overfitting~\cite{craig}.
Therefore, we decided to apply K-fold Cross-validation technique as it gave better performance compared to not applying K-fold Cross-validation technique
(see last section).
